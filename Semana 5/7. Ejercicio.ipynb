{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad48d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# EJERCICIO PRÁCTICO: INGENIERÍA DE CARACTERÍSTICAS\n",
    "# ======================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "\n",
    "# --------------------------------------\n",
    "# PARTE 1: ANÁLISIS EXPLORATORIO\n",
    "# --------------------------------------\n",
    "# Generamos datos sintéticos\n",
    "np.random.seed(123)\n",
    "horas_estudio = np.random.normal(15, 5, 100)\n",
    "calificaciones = 50 + 2*horas_estudio + np.random.normal(0, 8, 100)\n",
    "tiempo_descanso = np.random.exponential(10, 100)\n",
    "edad = np.random.randint(18, 25, 100)\n",
    "\n",
    "# Creamos un DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'horas_estudio': horas_estudio,\n",
    "    'calificaciones': calificaciones,\n",
    "    'tiempo_descanso': tiempo_descanso,\n",
    "    'edad': edad\n",
    "})\n",
    "\n",
    "# Añadimos outliers\n",
    "data.loc[10] = [40, 30, 50, 30]  # outlier 1\n",
    "data.loc[20] = [2, 90, 1, 17]     # outlier 2\n",
    "\n",
    "# 1. Visualización inicial\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(data.columns):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(data[col], bins=15, alpha=0.7)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.xlabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pregunta 1: \n",
    "# ¿Qué características tienen distribución sesgada? \n",
    "# ¿Qué características tienen escalas diferentes?\n",
    "# Respuesta: [COMPLETAR]\n",
    "\n",
    "# --------------------------------------\n",
    "# PARTE 2: ESCALADO DE CARACTERÍSTICAS\n",
    "# --------------------------------------\n",
    "# 2. Aplicar StandardScaler\n",
    "scaler_z = StandardScaler()\n",
    "data_z = pd.DataFrame(scaler_z.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# 3. Aplicar MinMaxScaler (a rango [0, 1])\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax = pd.DataFrame(scaler_minmax.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Visualización comparativa\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot(data.values)\n",
    "plt.xticks(range(1, len(data.columns)+1), data.columns)\n",
    "plt.title('Datos Originales')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(data_z.values)\n",
    "plt.xticks(range(1, len(data.columns)+1), data.columns)\n",
    "plt.title('StandardScaler')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot(data_minmax.values)\n",
    "plt.xticks(range(1, len(data.columns)+1), data.columns)\n",
    "plt.title('MinMaxScaler [0-1]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pregunta 2: \n",
    "# ¿Cómo afectan los outliers a cada método de escalado?\n",
    "# ¿Qué método sería más adecuado para un modelo KNN y por qué?\n",
    "# Respuesta: [COMPLETAR]\n",
    "\n",
    "# --------------------------------------\n",
    "# PARTE 3: TRANSFORMACIONES\n",
    "# --------------------------------------\n",
    "# 4. Aplicar transformación logarítmica a 'tiempo_descanso'\n",
    "data_log = data.copy()\n",
    "# COMPLETAR: Aplicar transformación logarítmica (recuerda sumar 1 para evitar log(0))\n",
    "data_log['tiempo_descanso'] = \n",
    "\n",
    "# 5. Calcular sesgo (skewness) antes y después\n",
    "skew_original = stats.skew(data['tiempo_descanso'])\n",
    "skew_log = stats.skew(data_log['tiempo_descanso'])\n",
    "\n",
    "print(f\"Sesgo original: {skew_original:.2f}\")\n",
    "print(f\"Sesgo después de log: {skew_log:.2f}\")\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data['tiempo_descanso'], bins=15)\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data_log['tiempo_descanso'], bins=15)\n",
    "plt.title('Transformación Logarítmica')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pregunta 3: \n",
    "# ¿Por qué es importante reducir el sesgo en las características?\n",
    "# ¿Qué otras transformaciones podrían ser útiles para estos datos?\n",
    "# Respuesta: [COMPLETAR]\n",
    "\n",
    "# --------------------------------------\n",
    "# PARTE 4: PCA Y REDUCCIÓN DE DIMENSIONALIDAD\n",
    "# --------------------------------------\n",
    "# 6. PCA sin escalado\n",
    "pca_raw = PCA()\n",
    "# COMPLETAR: Ajustar PCA a los datos originales\n",
    "\n",
    "# 7. PCA con StandardScaler\n",
    "pca_scaled = PCA()\n",
    "# COMPLETAR: Ajustar PCA a los datos escalados\n",
    "\n",
    "# Varianza explicada\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# COMPLETAR: Graficar varianza acumulada para PCA sin escalado\n",
    "plt.title('Varianza explicada (sin escalar)')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza acumulada')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# COMPLETAR: Graficar varianza acumulada para PCA con escalado\n",
    "plt.title('Varianza explicada (con escalado)')\n",
    "plt.xlabel('Número de componentes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Proyección de datos en 2 componentes\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# COMPLETAR: Graficar proyección de datos sin escalado\n",
    "plt.scatter(..., ..., c=data['calificaciones'])\n",
    "plt.colorbar(label='Calificaciones')\n",
    "plt.title('PCA sin escalado')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# COMPLETAR: Graficar proyección de datos con escalado\n",
    "plt.scatter(..., ..., c=data['calificaciones'])\n",
    "plt.colorbar(label='Calificaciones')\n",
    "plt.title('PCA con StandardScaler')\n",
    "plt.xlabel('PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pregunta 4: \n",
    "# ¿Por qué los resultados de PCA son tan diferentes con y sin escalado?\n",
    "# ¿Cuántos componentes se necesitan para explicar el 95% de la varianza en cada caso?\n",
    "# Respuesta: [COMPLETAR]\n",
    "\n",
    "# --------------------------------------\n",
    "# PARTE 5: INTERPRETACIÓN DE COMPONENTES\n",
    "# --------------------------------------\n",
    "# 9. Función para imprimir componentes\n",
    "def print_components(pca, features):\n",
    "    for i, component in enumerate(pca.components_):\n",
    "        print(f\"Componente Principal {i+1}:\")\n",
    "        for j, weight in enumerate(component):\n",
    "            print(f\"  {features[j]}: {weight:.3f}\")\n",
    "        print(f\"  Varianza explicada: {pca.explained_variance_ratio_[i]:.2%}\")\n",
    "        print()\n",
    "\n",
    "print(\"=== SIN ESCALAR ===\")\n",
    "print_components(pca_raw, data.columns)\n",
    "\n",
    "print(\"\\n=== CON STANDARDSCALER ===\")\n",
    "print_components(pca_scaled, data.columns)\n",
    "\n",
    "# Pregunta 5: \n",
    "# ¿Qué características contribuyen más al primer componente principal en cada caso?\n",
    "# ¿Por qué PCA con escalado da una interpretación más equilibrada?\n",
    "# Respuesta: [COMPLETAR]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
